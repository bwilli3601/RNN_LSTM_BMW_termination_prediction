{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMW data cleaning and randominzation for export to csvs for MIT-NorthStar project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import itertools\n",
    "from statistics import stdev \n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#make sure in HR environment\n",
    "import argparse\n",
    "import hashlib\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto import Random\n",
    "from datetime import datetime\n",
    "#import pandasql as ps\n",
    "\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn import tree\n",
    "\n",
    "# relevant tensorflow imports:\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "import copy\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all data from oracle connections to TS_INFO table and actuals punch data stored in HIVE\n",
    "\n",
    "Used bmw_data_cleaning.py file to generate csvs for use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmw = pd.read_csv(\"bmw_demo.csv\",\n",
    "                     index_col=[0])\n",
    "\n",
    "#cost-center headcount, gender counts, and avg tenure per month/shift/cc\n",
    "cc_grp = pd.read_csv(\"cc_grp.csv\",\n",
    "                    index_col=[0])\n",
    "\n",
    "\n",
    "#daily quality for assembly halls 50 and 52\n",
    "quality_daily_hall = pd.read_csv(\"quality_daily_hall.csv\")\n",
    "\n",
    "actuals = pd.read_csv(\"actual_demo.csv\",\n",
    "                      index_col=[0])\n",
    "\n",
    "plant_totals = pd.read_csv(\"plant_totals.csv\")\n",
    "\n",
    "#bmw attendance points\n",
    "\n",
    "bmw_points = pd.read_csv(\"bmw_points_200114.csv\")\n",
    "\n",
    "df_ejsi = pd.read_csv(\"df_ejsi.csv\")\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_totals = plant_totals[plant_totals.date_month> \"2018-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejsi = df_ejsi[df_ejsi.start_dt > \"2019-01-01\"]\n",
    "df_bmw = df_bmw[df_bmw.birth_year<2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bmw.birth_year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>cost_center_name</th>\n",
       "      <th>org_unit</th>\n",
       "      <th>dept</th>\n",
       "      <th>badge</th>\n",
       "      <th>status</th>\n",
       "      <th>ee_type</th>\n",
       "      <th>ta_admin_num</th>\n",
       "      <th>ta_admin_name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>zip_code_type</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>city</th>\n",
       "      <th>ws_rule</th>\n",
       "      <th>ws_text</th>\n",
       "      <th>daily_hours</th>\n",
       "      <th>race</th>\n",
       "      <th>last_date_worked</th>\n",
       "      <th>start_date_month</th>\n",
       "      <th>end_date_month</th>\n",
       "      <th>first_punch_cost_center</th>\n",
       "      <th>cost_center_orig</th>\n",
       "      <th>cost_center</th>\n",
       "      <th>ejsi_cc</th>\n",
       "      <th>first_ejsi_start_dt</th>\n",
       "      <th>first_ejsi_proc_desc</th>\n",
       "      <th>first_ejsi_cost_center</th>\n",
       "      <th>hall</th>\n",
       "      <th>tenure_yrs</th>\n",
       "      <th>age_at_hire</th>\n",
       "      <th>shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [start_date, end_date, cost_center_name, org_unit, dept, badge, status, ee_type, ta_admin_num, ta_admin_name, birth_year, gender, zip_code_type, zip_code, city, ws_rule, ws_text, daily_hours, race, last_date_worked, start_date_month, end_date_month, first_punch_cost_center, cost_center_orig, cost_center, ejsi_cc, first_ejsi_start_dt, first_ejsi_proc_desc, first_ejsi_cost_center, hall, tenure_yrs, age_at_hire, shift]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bmw[df_bmw.birth_year>2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_date</th>\n",
       "      <th>shift</th>\n",
       "      <th>hall</th>\n",
       "      <th>volume</th>\n",
       "      <th>repair_minutes</th>\n",
       "      <th>defect_date</th>\n",
       "      <th>count_non_dp_vins_hall</th>\n",
       "      <th>rmu_hall</th>\n",
       "      <th>dpu_hall</th>\n",
       "      <th>dp_f1_hall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2592</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15028.5</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>186.0</td>\n",
       "      <td>58.025097</td>\n",
       "      <td>0.718147</td>\n",
       "      <td>0.281853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2593</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>52</td>\n",
       "      <td>279.0</td>\n",
       "      <td>19112.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>284.0</td>\n",
       "      <td>68.501792</td>\n",
       "      <td>1.017921</td>\n",
       "      <td>-0.017921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2594</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>50</td>\n",
       "      <td>323.0</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>255.0</td>\n",
       "      <td>31.941176</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2595</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>52</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15299.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>363.0</td>\n",
       "      <td>49.192926</td>\n",
       "      <td>1.167203</td>\n",
       "      <td>-0.167203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2596</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>305.0</td>\n",
       "      <td>13044.0</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>186.0</td>\n",
       "      <td>42.767213</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.390164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_date shift  hall  volume  repair_minutes defect_date  \\\n",
       "2592  2018-01-02     A    50   259.0         15028.5  2018-01-02   \n",
       "2593  2018-01-02     A    52   279.0         19112.0  2018-01-02   \n",
       "2594  2018-01-02     B    50   323.0         10317.0  2018-01-02   \n",
       "2595  2018-01-02     B    52   311.0         15299.0  2018-01-02   \n",
       "2596  2018-01-03     A    50   305.0         13044.0  2018-01-03   \n",
       "\n",
       "      count_non_dp_vins_hall   rmu_hall  dpu_hall  dp_f1_hall  \n",
       "2592                   186.0  58.025097  0.718147    0.281853  \n",
       "2593                   284.0  68.501792  1.017921   -0.017921  \n",
       "2594                   255.0  31.941176  0.789474    0.210526  \n",
       "2595                   363.0  49.192926  1.167203   -0.167203  \n",
       "2596                   186.0  42.767213  0.609836    0.390164  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_daily_hall = quality_daily_hall[quality_daily_hall.f1_date>'2018-01-01']\n",
    "quality_daily_hall = quality_daily_hall.drop(quality_daily_hall.columns[0], axis=1)\n",
    "quality_daily_hall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(df_bmw['race'], df_bmw['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>badge</th>\n",
       "      <th>name</th>\n",
       "      <th>cost_center</th>\n",
       "      <th>att_date</th>\n",
       "      <th>att_code</th>\n",
       "      <th>att_desc</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>Tim G Howe</td>\n",
       "      <td>2666</td>\n",
       "      <td>10/10/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>Tim G Howe</td>\n",
       "      <td>2666</td>\n",
       "      <td>10/24/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>Tim G Howe</td>\n",
       "      <td>2666</td>\n",
       "      <td>10/25/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>Philip A Richards</td>\n",
       "      <td>2830</td>\n",
       "      <td>1/13/20</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>298</td>\n",
       "      <td>Edward L Kearse</td>\n",
       "      <td>1856</td>\n",
       "      <td>11/6/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   badge               name  cost_center  att_date  att_code  \\\n",
       "0    124         Tim G Howe         2666  10/10/19      9000   \n",
       "1    124         Tim G Howe         2666  10/24/19      9000   \n",
       "2    124         Tim G Howe         2666  10/25/19      9000   \n",
       "3    139  Philip A Richards         2830   1/13/20      9000   \n",
       "4    298    Edward L Kearse         1856   11/6/19      9000   \n",
       "\n",
       "            att_desc  hours  \n",
       "0  Daily Occurrences    8.0  \n",
       "1  Daily Occurrences    4.0  \n",
       "2  Daily Occurrences    4.0  \n",
       "3  Daily Occurrences    4.0  \n",
       "4  Daily Occurrences    4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmw_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict who will leave in next 30 days\n",
    "\n",
    "For those who have already left, get the averages for the month before they left\n",
    "For those still active, get averages for the month before the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the last month they were active\n",
    "\n",
    "#df_bmw['last_date_worked'] = pd.to_datetime(np.where(df_bmw['status']=='Terminted', df_bmw['end_date'],\n",
    "#                                      datetime.now().strftime(\"%Y-%m-%d\")))\n",
    "                                \n",
    "#df_bmw['last_month_worked'] = df_bmw['last_date_worked'].dt.to_period('M')                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>cost_center_name</th>\n",
       "      <th>org_unit</th>\n",
       "      <th>dept</th>\n",
       "      <th>badge</th>\n",
       "      <th>status</th>\n",
       "      <th>ee_type</th>\n",
       "      <th>ta_admin_num</th>\n",
       "      <th>ta_admin_name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>zip_code_type</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>city</th>\n",
       "      <th>ws_rule</th>\n",
       "      <th>ws_text</th>\n",
       "      <th>daily_hours</th>\n",
       "      <th>race</th>\n",
       "      <th>last_date_worked</th>\n",
       "      <th>start_date_month</th>\n",
       "      <th>end_date_month</th>\n",
       "      <th>first_punch_cost_center</th>\n",
       "      <th>cost_center_orig</th>\n",
       "      <th>cost_center</th>\n",
       "      <th>ejsi_cc</th>\n",
       "      <th>first_ejsi_start_dt</th>\n",
       "      <th>first_ejsi_proc_desc</th>\n",
       "      <th>first_ejsi_cost_center</th>\n",
       "      <th>hall</th>\n",
       "      <th>tenure_yrs</th>\n",
       "      <th>age_at_hire</th>\n",
       "      <th>shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVO</td>\n",
       "      <td>80001887</td>\n",
       "      <td>TX-453</td>\n",
       "      <td>120</td>\n",
       "      <td>Active</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>A27</td>\n",
       "      <td>Todd Hill</td>\n",
       "      <td>1964</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mailing Address</td>\n",
       "      <td>29645.0</td>\n",
       "      <td>Gray Court</td>\n",
       "      <td>APBC</td>\n",
       "      <td>A-Shift Paint App B/C</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-Hispanic/Latino</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1994-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>1856</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.046575</td>\n",
       "      <td>29.953425</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>Machine Shop/Gun Sho</td>\n",
       "      <td>80001854</td>\n",
       "      <td>TX-212</td>\n",
       "      <td>124</td>\n",
       "      <td>Retiree</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1954</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mailing Address</td>\n",
       "      <td>29369.0</td>\n",
       "      <td>moore</td>\n",
       "      <td>AICP</td>\n",
       "      <td>A-Shift ICP</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-Hispanic/Latino</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>1994-01</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>2666</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.821918</td>\n",
       "      <td>40.178082</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assem. Quality</td>\n",
       "      <td>80000650</td>\n",
       "      <td>TX-40</td>\n",
       "      <td>139</td>\n",
       "      <td>Active</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>Y92</td>\n",
       "      <td>Kyle K Brooks</td>\n",
       "      <td>1970</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mailing Address</td>\n",
       "      <td>29323.0</td>\n",
       "      <td>Chesnee</td>\n",
       "      <td>AFE2</td>\n",
       "      <td>A-Shift Facilities Early</td>\n",
       "      <td>10</td>\n",
       "      <td>Non-Hispanic/Latino</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1994-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>2830</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.046575</td>\n",
       "      <td>23.953425</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>Underbody/Steerng Kn</td>\n",
       "      <td>80002975</td>\n",
       "      <td>TX-436</td>\n",
       "      <td>140</td>\n",
       "      <td>Retiree</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955</td>\n",
       "      <td>Female</td>\n",
       "      <td>Mailing Address</td>\n",
       "      <td>29302.0</td>\n",
       "      <td>Spartanburg</td>\n",
       "      <td>APBC</td>\n",
       "      <td>A-Shift Paint App B/C</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-Hispanic/Latino</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>1994-01</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>1807</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.821918</td>\n",
       "      <td>39.178082</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1994-02-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICP</td>\n",
       "      <td>80001886</td>\n",
       "      <td>TX-452</td>\n",
       "      <td>185</td>\n",
       "      <td>Active</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>Y75</td>\n",
       "      <td>Brian Kelly Reynolds</td>\n",
       "      <td>1959</td>\n",
       "      <td>Female</td>\n",
       "      <td>Mailing Address</td>\n",
       "      <td>29681.0</td>\n",
       "      <td>Simpsonville</td>\n",
       "      <td>APBC</td>\n",
       "      <td>A-Shift Paint App B/C</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-Hispanic/Latino</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1994-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.915068</td>\n",
       "      <td>35.084932</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date    end_date      cost_center_name  org_unit    dept  badge  \\\n",
       "0  1994-01-04         NaN                   SVO  80001887  TX-453    120   \n",
       "1  1994-01-04  2019-10-25  Machine Shop/Gun Sho  80001854  TX-212    124   \n",
       "2  1994-01-04         NaN        Assem. Quality  80000650   TX-40    139   \n",
       "3  1994-01-04  2019-10-25  Underbody/Steerng Kn  80002975  TX-436    140   \n",
       "4  1994-02-21         NaN                   ICP  80001886  TX-452    185   \n",
       "\n",
       "    status ee_type ta_admin_num         ta_admin_name  birth_year  gender  \\\n",
       "0   Active  Hourly          A27             Todd Hill        1964    Male   \n",
       "1  Retiree  Hourly          NaN                   NaN        1954    Male   \n",
       "2   Active  Hourly          Y92         Kyle K Brooks        1970    Male   \n",
       "3  Retiree  Hourly          NaN                   NaN        1955  Female   \n",
       "4   Active  Hourly          Y75  Brian Kelly Reynolds        1959  Female   \n",
       "\n",
       "     zip_code_type  zip_code          city ws_rule                   ws_text  \\\n",
       "0  Mailing Address   29645.0    Gray Court    APBC     A-Shift Paint App B/C   \n",
       "1  Mailing Address   29369.0         moore    AICP               A-Shift ICP   \n",
       "2  Mailing Address   29323.0       Chesnee    AFE2  A-Shift Facilities Early   \n",
       "3  Mailing Address   29302.0   Spartanburg    APBC     A-Shift Paint App B/C   \n",
       "4  Mailing Address   29681.0  Simpsonville    APBC     A-Shift Paint App B/C   \n",
       "\n",
       "   daily_hours                 race last_date_worked start_date_month  \\\n",
       "0            8  Non-Hispanic/Latino       2020-01-15          1994-01   \n",
       "1            8  Non-Hispanic/Latino       2019-10-25          1994-01   \n",
       "2           10  Non-Hispanic/Latino       2020-01-15          1994-01   \n",
       "3            8  Non-Hispanic/Latino       2019-10-25          1994-01   \n",
       "4            8  Non-Hispanic/Latino       2020-01-15          1994-02   \n",
       "\n",
       "  end_date_month  first_punch_cost_center  cost_center_orig  cost_center  \\\n",
       "0            NaN                   1856.0              1856       1856.0   \n",
       "1        2019-10                   2666.0              2666       2666.0   \n",
       "2            NaN                   2830.0              2830       2830.0   \n",
       "3        2019-10                   1807.0              1807       1807.0   \n",
       "4            NaN                   1900.0              1900       1900.0   \n",
       "\n",
       "   ejsi_cc first_ejsi_start_dt first_ejsi_proc_desc  first_ejsi_cost_center  \\\n",
       "0      NaN                 NaN                  NaN                     NaN   \n",
       "1      NaN                 NaN                  NaN                     NaN   \n",
       "2      NaN                 NaN                  NaN                     NaN   \n",
       "3      NaN                 NaN                  NaN                     NaN   \n",
       "4      NaN                 NaN                  NaN                     NaN   \n",
       "\n",
       "   hall  tenure_yrs  age_at_hire shift  \n",
       "0  50.0   26.046575    29.953425     A  \n",
       "1   NaN   25.821918    40.178082     A  \n",
       "2  50.0   26.046575    23.953425     A  \n",
       "3  50.0   25.821918    39.178082     A  \n",
       "4   NaN   25.915068    35.084932     A  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bmw.head()\n",
    "#last date worked filled into be current date as of 1-15-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get monthly average quality KPIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift</th>\n",
       "      <th>work_date_month</th>\n",
       "      <th>cost_center</th>\n",
       "      <th>headcount_mau_cc</th>\n",
       "      <th>headcount_bmw_cc</th>\n",
       "      <th>total_headcount_cc</th>\n",
       "      <th>count_female_cc</th>\n",
       "      <th>count_male_cc</th>\n",
       "      <th>count_nogender_cc</th>\n",
       "      <th>percentage_female_cc</th>\n",
       "      <th>avg_tenure_cc</th>\n",
       "      <th>avg_tenure_bmw_cc</th>\n",
       "      <th>count_bmw_employees_tenure</th>\n",
       "      <th>avg_tenure_mau_cc</th>\n",
       "      <th>count_mau_employees_tenure</th>\n",
       "      <th>count_hired_mau</th>\n",
       "      <th>count_hired_bmw</th>\n",
       "      <th>count_termianted_bmw</th>\n",
       "      <th>count_termianted_mau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>1.171542</td>\n",
       "      <td>17.191096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.066745</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>2.613918</td>\n",
       "      <td>11.825342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.812924</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>3.764000</td>\n",
       "      <td>10.542009</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.839726</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>5.317310</td>\n",
       "      <td>15.943836</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.016103</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>9.761644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.761644</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shift work_date_month  cost_center  headcount_mau_cc  headcount_bmw_cc  \\\n",
       "0     A         2018-04       1026.0              67.0               5.0   \n",
       "1     A         2018-04       1317.0              46.0               4.0   \n",
       "2     A         2018-04       1319.0              26.0               4.0   \n",
       "3     A         2018-04       1340.0              33.0               4.0   \n",
       "4     A         2018-04       1341.0               8.0               0.0   \n",
       "\n",
       "   total_headcount_cc  count_female_cc  count_male_cc  count_nogender_cc  \\\n",
       "0                72.0             22.0           39.0                0.0   \n",
       "1                50.0             11.0           37.0                0.0   \n",
       "2                30.0             12.0           36.0                1.0   \n",
       "3                37.0              7.0           46.0                0.0   \n",
       "4                 8.0              1.0            4.0                0.0   \n",
       "\n",
       "   percentage_female_cc  avg_tenure_cc  avg_tenure_bmw_cc  \\\n",
       "0              0.360656       1.171542          17.191096   \n",
       "1              0.229167       2.613918          11.825342   \n",
       "2              0.244898       3.764000          10.542009   \n",
       "3              0.132075       5.317310          15.943836   \n",
       "4              0.200000       9.761644                NaN   \n",
       "\n",
       "   count_bmw_employees_tenure  avg_tenure_mau_cc  count_mau_employees_tenure  \\\n",
       "0                         4.0           0.066745                        57.0   \n",
       "1                         4.0           1.812924                        44.0   \n",
       "2                         6.0           2.839726                        43.0   \n",
       "3                         6.0           4.016103                        47.0   \n",
       "4                         NaN           9.761644                         5.0   \n",
       "\n",
       "   count_hired_mau  count_hired_bmw  count_termianted_bmw  \\\n",
       "0              NaN              NaN                   NaN   \n",
       "1              4.0              NaN                   NaN   \n",
       "2              NaN              NaN                   NaN   \n",
       "3              6.0              NaN                   NaN   \n",
       "4              2.0              NaN                   NaN   \n",
       "\n",
       "   count_termianted_mau  \n",
       "0                   NaN  \n",
       "1                   2.0  \n",
       "2                   1.0  \n",
       "3                   1.0  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_grp.head()\n",
    "\n",
    "#headcount and gender counts already done at month level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_date</th>\n",
       "      <th>shift</th>\n",
       "      <th>hall</th>\n",
       "      <th>volume</th>\n",
       "      <th>repair_minutes</th>\n",
       "      <th>defect_date</th>\n",
       "      <th>count_non_dp_vins_hall</th>\n",
       "      <th>rmu_hall</th>\n",
       "      <th>dpu_hall</th>\n",
       "      <th>dp_f1_hall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2592</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15028.5</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>186.0</td>\n",
       "      <td>58.025097</td>\n",
       "      <td>0.718147</td>\n",
       "      <td>0.281853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2593</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>52</td>\n",
       "      <td>279.0</td>\n",
       "      <td>19112.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>284.0</td>\n",
       "      <td>68.501792</td>\n",
       "      <td>1.017921</td>\n",
       "      <td>-0.017921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2594</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>50</td>\n",
       "      <td>323.0</td>\n",
       "      <td>10317.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>255.0</td>\n",
       "      <td>31.941176</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2595</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>52</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15299.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>363.0</td>\n",
       "      <td>49.192926</td>\n",
       "      <td>1.167203</td>\n",
       "      <td>-0.167203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2596</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>305.0</td>\n",
       "      <td>13044.0</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>186.0</td>\n",
       "      <td>42.767213</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.390164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1_date shift  hall  volume  repair_minutes defect_date  \\\n",
       "2592  2018-01-02     A    50   259.0         15028.5  2018-01-02   \n",
       "2593  2018-01-02     A    52   279.0         19112.0  2018-01-02   \n",
       "2594  2018-01-02     B    50   323.0         10317.0  2018-01-02   \n",
       "2595  2018-01-02     B    52   311.0         15299.0  2018-01-02   \n",
       "2596  2018-01-03     A    50   305.0         13044.0  2018-01-03   \n",
       "\n",
       "      count_non_dp_vins_hall   rmu_hall  dpu_hall  dp_f1_hall  \n",
       "2592                   186.0  58.025097  0.718147    0.281853  \n",
       "2593                   284.0  68.501792  1.017921   -0.017921  \n",
       "2594                   255.0  31.941176  0.789474    0.210526  \n",
       "2595                   363.0  49.192926  1.167203   -0.167203  \n",
       "2596                   186.0  42.767213  0.609836    0.390164  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_daily_hall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_daily_hall['f1_month'] = pd.to_datetime(quality_daily_hall['f1_date']).dt.to_period('M')\n",
    "\n",
    "#sum up all volume created in that month\n",
    "\n",
    "quality_daily_hall_monthly = quality_daily_hall.groupby([\n",
    "                                                         'f1_month',\n",
    "                                                            'shift',\n",
    "                                                            'hall'],\n",
    "                                    as_index=False).agg({\n",
    "                                        'volume':'sum',\n",
    "                                        'repair_minutes':'sum',\n",
    "                                        'count_non_dp_vins_hall':'sum'})\n",
    "\n",
    "\n",
    "quality_daily_hall_monthly['RMU_hall_month'] = quality_daily_hall_monthly['repair_minutes'] / (quality_daily_hall_monthly['volume']).astype('float')\n",
    "quality_daily_hall_monthly['dpu_hall_month'] = quality_daily_hall_monthly['count_non_dp_vins_hall']/ quality_daily_hall_monthly['volume']\n",
    "\n",
    "quality_daily_hall_monthly['f1_dp_hall_month'] = (quality_daily_hall_monthly['volume'] - quality_daily_hall_monthly['count_non_dp_vins_hall'])/ quality_daily_hall_monthly['volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92 entries, 0 to 91\n",
      "Data columns (total 9 columns):\n",
      "f1_month                  92 non-null period[M]\n",
      "shift                     92 non-null object\n",
      "hall                      92 non-null int64\n",
      "volume                    92 non-null float64\n",
      "repair_minutes            92 non-null float64\n",
      "count_non_dp_vins_hall    92 non-null float64\n",
      "RMU_hall_month            92 non-null float64\n",
      "dpu_hall_month            92 non-null float64\n",
      "f1_dp_hall_month          92 non-null float64\n",
      "dtypes: float64(6), int64(1), object(1), period[M](1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "quality_daily_hall_monthly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_month</th>\n",
       "      <th>shift</th>\n",
       "      <th>hall</th>\n",
       "      <th>volume</th>\n",
       "      <th>repair_minutes</th>\n",
       "      <th>count_non_dp_vins_hall</th>\n",
       "      <th>RMU_hall_month</th>\n",
       "      <th>dpu_hall_month</th>\n",
       "      <th>f1_dp_hall_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>8663.0</td>\n",
       "      <td>431810.0</td>\n",
       "      <td>4442.0</td>\n",
       "      <td>49.845319</td>\n",
       "      <td>0.512755</td>\n",
       "      <td>0.487245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>A</td>\n",
       "      <td>52</td>\n",
       "      <td>7625.0</td>\n",
       "      <td>528209.5</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>69.273377</td>\n",
       "      <td>0.773770</td>\n",
       "      <td>0.226230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>B</td>\n",
       "      <td>50</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>393935.0</td>\n",
       "      <td>5975.0</td>\n",
       "      <td>42.299474</td>\n",
       "      <td>0.641576</td>\n",
       "      <td>0.358424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>B</td>\n",
       "      <td>52</td>\n",
       "      <td>8274.0</td>\n",
       "      <td>507186.0</td>\n",
       "      <td>6795.0</td>\n",
       "      <td>61.298767</td>\n",
       "      <td>0.821247</td>\n",
       "      <td>0.178753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>9423.0</td>\n",
       "      <td>455685.5</td>\n",
       "      <td>4380.0</td>\n",
       "      <td>48.358856</td>\n",
       "      <td>0.464820</td>\n",
       "      <td>0.535180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  f1_month shift  hall  volume  repair_minutes  count_non_dp_vins_hall  \\\n",
       "0  2018-01     A    50  8663.0        431810.0                  4442.0   \n",
       "1  2018-01     A    52  7625.0        528209.5                  5900.0   \n",
       "2  2018-01     B    50  9313.0        393935.0                  5975.0   \n",
       "3  2018-01     B    52  8274.0        507186.0                  6795.0   \n",
       "4  2018-02     A    50  9423.0        455685.5                  4380.0   \n",
       "\n",
       "   RMU_hall_month  dpu_hall_month  f1_dp_hall_month  \n",
       "0       49.845319        0.512755          0.487245  \n",
       "1       69.273377        0.773770          0.226230  \n",
       "2       42.299474        0.641576          0.358424  \n",
       "3       61.298767        0.821247          0.178753  \n",
       "4       48.358856        0.464820          0.535180  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_daily_hall_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monthly sum of points per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>badge</th>\n",
       "      <th>name</th>\n",
       "      <th>cost_center</th>\n",
       "      <th>att_date</th>\n",
       "      <th>att_code</th>\n",
       "      <th>att_desc</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>Tim G Howe</td>\n",
       "      <td>2666</td>\n",
       "      <td>10/10/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>Tim G Howe</td>\n",
       "      <td>2666</td>\n",
       "      <td>10/24/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>Tim G Howe</td>\n",
       "      <td>2666</td>\n",
       "      <td>10/25/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>Philip A Richards</td>\n",
       "      <td>2830</td>\n",
       "      <td>1/13/20</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>298</td>\n",
       "      <td>Edward L Kearse</td>\n",
       "      <td>1856</td>\n",
       "      <td>11/6/19</td>\n",
       "      <td>9000</td>\n",
       "      <td>Daily Occurrences</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   badge               name  cost_center  att_date  att_code  \\\n",
       "0    124         Tim G Howe         2666  10/10/19      9000   \n",
       "1    124         Tim G Howe         2666  10/24/19      9000   \n",
       "2    124         Tim G Howe         2666  10/25/19      9000   \n",
       "3    139  Philip A Richards         2830   1/13/20      9000   \n",
       "4    298    Edward L Kearse         1856   11/6/19      9000   \n",
       "\n",
       "            att_desc  hours  \n",
       "0  Daily Occurrences    8.0  \n",
       "1  Daily Occurrences    4.0  \n",
       "2  Daily Occurrences    4.0  \n",
       "3  Daily Occurrences    4.0  \n",
       "4  Daily Occurrences    4.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmw_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>badge</th>\n",
       "      <th>att_month</th>\n",
       "      <th>att_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>298</td>\n",
       "      <td>2019-11</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>2019-05</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>397</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   badge att_month  att_points\n",
       "0    124   2019-10        16.0\n",
       "1    139   2020-01         4.0\n",
       "2    298   2019-11        12.0\n",
       "3    375   2019-05         5.0\n",
       "4    397   2020-01        32.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmw_points['att_month'] = pd.to_datetime(bmw_points['att_date']).dt.to_period('M')\n",
    "\n",
    "bmw_points_monthly = bmw_points.groupby(['badge', 'att_month'], as_index=False).agg({'hours':'sum'})\n",
    "\n",
    "bmw_points_monthly.rename(columns={'hours':'att_points'}, inplace=True)\n",
    "bmw_points_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function is_scalar> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-17a59827fb78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hours_at_loc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_dt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_ejsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'minutes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;31m#get amount of hours spent at each station\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_ejsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36mcomponents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;36m4\u001b[0m     \u001b[0;36m0\u001b[0m      \u001b[0;36m0\u001b[0m        \u001b[0;36m0\u001b[0m        \u001b[0;36m4\u001b[0m             \u001b[0;36m0\u001b[0m             \u001b[0;36m0\u001b[0m            \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"  # noqa: E501\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m_getter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_create_delegator_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delegate_property_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_setter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/datetimelike.py\u001b[0m in \u001b[0;36m_delegate_property_get\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_delegate_property_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_properties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/timedeltas.py\u001b[0m in \u001b[0;36mcomponents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/timedeltas.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/timedeltas.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_isna_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecknull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# hack (for now) because MI registers as ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function is_scalar> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# get avg time spent on each location per person per month\n",
    "\n",
    "df_ejsi['end_dt'] = pd.to_datetime(df_ejsi['end_dt'])\n",
    "df_ejsi['start_dt'] = pd.to_datetime(df_ejsi['start_dt'])\n",
    "df_ejsi['hours_at_loc'] = (df_ejsi['end_dt'] - df_ejsi['start_dt']).dt.components['days']*24\\\n",
    "    +(df_ejsi['end_dt'] - df_ejsi['start_dt']).dt.components['hours']+((df_ejsi['end_dt'] - df_ejsi['start_dt']).dt.components['minutes'])/60 #get amount of hours spent at each station\n",
    "df_ejsi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EJSI most frequent sign in location, and avg time spent on each location per person per month\n",
    "\n",
    "df_ejsi['month'] = pd.to_datetime(df_ejsi['start_dt']).dt.to_period('M') #start date that they were workin on that line location\n",
    "\n",
    "df_ejsi_monthly_avg = df_ejsi.groupby(['badge', 'month'], as_index=False).agg({'hours_at_loc':['mean', 'max']})\n",
    "df_ejsi_monthly_avg.columns = ['badge', 'month','avg_hours_at_line_loc', 'max_hours_at_line_loc']\n",
    "\n",
    "df_ejsi_monthly = df_ejsi.groupby(['badge', 'month'], as_index=False)['line_loc'].agg(lambda x: pd.Series.mode(x)[0])\n",
    "\n",
    "\n",
    "#join in the avg time spent at any line location\n",
    "df_ejsi_monthly = df_ejsi_monthly.merge(df_ejsi_monthly_avg,\n",
    "                                       on=['badge', 'month'],\n",
    "                                       how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ejsi_monthly.columns = ['badge', 'ejsi_month', 'line_loc_mode', 'avg_hours_at_loc']\n",
    "df_ejsi_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual punch in averages per person month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals.head()\n",
    "actuals['work_date'] = pd.to_datetime(actuals['work_date'])\n",
    "actuals['month'] = actuals['work_date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals['description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_monthly_avg = actuals[actuals['description']=='Regular Hours'].groupby(['badge', 'month'], as_index=False)\\\n",
    ".agg({'num_hours':['mean', 'sum']})\n",
    "\n",
    "actuals_monthly_avg.columns = ['badge', 'month', 'avg_reg_hours', 'sum_reg_hours']\n",
    "actuals_monthly_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OT_list = ['Double Time', 'DTime: Premium', 'Double time', 'DTime:Premium']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals['month'] = pd.to_datetime(actuals['work_date']).dt.to_period('M')\n",
    "#gets the most frequent cost-center\n",
    "actuals_monthly = actuals.groupby(['badge', 'month'], as_index=False)['cost_center'].agg(lambda x: pd.Series.mode(x))\n",
    "\n",
    "#avg normal hours\n",
    "actuals_monthly_avg_OT = actuals[actuals.description.isin(OT_list)].groupby(['badge', 'month'], as_index=False)\\\n",
    ".agg({'num_hours':['mean', 'sum']})\n",
    "actuals_monthly_avg_OT.columns = ['badge', 'month', 'avg_OT_hours', 'sum_OT_hours']\n",
    "\n",
    "#total overtime hours per month, and avg hours per month\n",
    "actuals_monthly_avg_reg = actuals[actuals['description']=='Regular Hours'].groupby(['badge', 'month'], as_index=False)\\\n",
    ".agg({'num_hours':['mean', 'sum']})\n",
    "actuals_monthly_avg_reg.columns = ['badge', 'month', 'avg_reg_hours', 'sum_reg_hours']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_monthly_avg_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the mode, or most frequent cc to the avg time clocked in per day for that month/person\n",
    "actuals_monthly = actuals_monthly.merge(actuals_monthly_avg_reg,\n",
    "                                       on=['badge', 'month'],\n",
    "                                       how='left')\n",
    "\n",
    "#merge in overtime\n",
    "actuals_monthly = actuals_monthly.merge(actuals_monthly_avg_OT,\n",
    "                                       on=['badge', 'month'],\n",
    "                                       how='left')\n",
    "\n",
    "#actuals_monthly.head()\n",
    "\n",
    "#print(actuals_monthly.iloc[3000, actuals_monthly.columns.get_loc('avg_reg_hours')])\n",
    "#print(actuals_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_monthly_avg_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_monthly_avg_OT\n",
    "\n",
    "# it seems that there is a lot more rows in actuals_monthly_avg_reg than in actuals_monthly_avg_OT and some badges...\n",
    "    # ... are only in one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create profile for each person. \n",
    "\n",
    "For active employees, it is whatever happened the month before our chosen cutoff month.\n",
    "For termianted employees, it is whatever happened the month before the month they were terminated in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only want to see people who were terminated after 2018-01, or who are still active\n",
    "\n",
    "df_bmw = df_bmw[((df_bmw.status=='Terminated') & (df_bmw.end_date >= \"2018-01-01\"))\\\n",
    "               | (df_bmw.status=='Active')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmw[df_bmw.end_date.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmw[(df_bmw.cost_center==1222) & (df_bmw.status=='Terminated')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmw[df_bmw.dept=='Inactive']\n",
    "\n",
    "# in df_bmw, remoe anybody in inactive department, as they are all terminated and are biasing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##testVar = df_bmw[df_bmw['status']=='Terminated']\n",
    "##xx=df_bmw.groupby(['status','dept'],\n",
    "##                 as_index=False)['ee_type'].count()\n",
    "##xx[xx.dept=='Inactive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_months =[]\n",
    "start1=[]\n",
    "end1=[]\n",
    "df_list = []\n",
    "\n",
    "for index, row in df_bmw.iterrows():\n",
    "    if df_bmw.loc[index, 'start_date'] < '2018-01-01':\n",
    "        start_date = '2018-01-01'\n",
    "    else:\n",
    "        start_date = df_bmw.loc[index, 'start_date']\n",
    "    #end_date = df_bmw.loc[index, 'last_date_worked']\n",
    "    months_worked = pd.date_range(start_date , df_bmw.loc[index, 'last_date_worked'], freq='MS').strftime(\"%Y-%m\").tolist()\n",
    "    \n",
    "    #create dataframe for each person\n",
    "    df = pd.DataFrame(months_worked)\n",
    "    df['badge'] = df_bmw.loc[index, 'badge']\n",
    "    #df.columns = ['month', 'badge']\n",
    "    \n",
    "    work_months.append(months_worked)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(work_months) #list\n",
    "#work_months[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it into 1 dataframe\n",
    "df_work_months = pd.concat(df_list)\n",
    "df_work_months.columns = ['month', 'badge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in the demographics for each person\n",
    "bmw_demo = df_bmw.drop(['ta_admin_num',\n",
    "                       'ta_admin_name', #terminated ppl do not have a ta_admin, so it would bias model\n",
    "                       'zip_code_type',\n",
    "                       'last_date_worked',\n",
    "                       'end_date_month',\n",
    "                        'first_ejsi_start_dt',\n",
    "                        'first_ejsi_proc_desc'],\n",
    "                        axis=1\n",
    "                       )\n",
    "\n",
    "df_work_months['month'] = df_work_months['month'].astype('str')\n",
    "\n",
    "employee_matrix = df_work_months.merge(bmw_demo,\n",
    "                         left_on=['badge'],\n",
    "                         right_on=['badge'],\n",
    "                         how='left')\n",
    "\n",
    "#redo tenure for each month\n",
    "\n",
    "employee_matrix['tenure_yrs'] = ((pd.to_datetime(employee_matrix['month']+'-01')\\\n",
    "                                - pd.to_datetime(employee_matrix['start_date'])).dt.days)/365\n",
    "\n",
    "employee_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in the bmw_points_monthly for each person\n",
    "bmw_points_monthly['att_month'] = bmw_points_monthly['att_month'].astype('str')\n",
    "\n",
    "employee_matrix = employee_matrix.merge(bmw_points_monthly,\n",
    "                         left_on=['badge', 'month'],\n",
    "                         right_on=['badge', 'att_month'],\n",
    "                         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in quality based on hall\n",
    "quality_daily_hall_monthly['f1_month'] = quality_daily_hall_monthly['f1_month'].astype('str')\n",
    "\n",
    "employee_matrix = employee_matrix.merge(quality_daily_hall_monthly,\n",
    "                         left_on=['hall', 'shift', 'month'],\n",
    "                         right_on=['hall', 'shift', 'f1_month'],\n",
    "                         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I suspect that it only has the values in the correct months, the data is probably fine for the sum and avg columns\n",
    "    # not gonna waste any more time looking at these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in actual hours worked each month\n",
    "\n",
    "employee_matrix = employee_matrix.merge(actuals_monthly.drop('cost_center', axis=1),\n",
    "                                        on=['badge', 'month'],\n",
    "                                        how='left')\n",
    "#all quality data is for dates up to that month end, ex if month is 2019-03, \n",
    "#the qulity data is aggregated for 2019-03-01 to 2019-03-31\n",
    "\n",
    "employee_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in df_ejsi_monthly\n",
    "\n",
    "employee_matrix = employee_matrix.merge(df_ejsi_monthly,\n",
    "                                       on=['badge','month'],\n",
    "                                       how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label if that person left next month or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_matrix['next_month'] = (pd.to_datetime(employee_matrix['month']+'-01')+timedelta(days=31)).dt.to_period('M')\n",
    "employee_matrix['next_month2'] = (pd.to_datetime(employee_matrix['month']+'-01')+timedelta(days=62)).dt.to_period('M')\n",
    "\n",
    "employee_matrix['label']= np.where((pd.to_datetime(employee_matrix['end_date']) >= pd.to_datetime(employee_matrix['next_month'].astype('str')+'-01'))\\\n",
    "                                   & (pd.to_datetime(employee_matrix['end_date']) <= pd.to_datetime(employee_matrix['next_month2'].astype('str')+'-01')),\n",
    "                                   1,\n",
    "                                   0)\n",
    "\n",
    "\n",
    "#remove that last entry whih is in the month that they left\n",
    "#since we are using the data for that month (ex month 2019-03 includes data from 2019-03-01 to 2019-03-31), \n",
    "# and that person termianted on 2019-04-10, for the month 2019-04 technically they were employeed for part of it, \n",
    "# but since they leave midway through we cannot use the enitre month of data to predict if they are going to leave\n",
    "employee_matrix = employee_matrix[(pd.to_datetime(employee_matrix['end_date'])) >= (pd.to_datetime(employee_matrix['next_month'].astype('str')+'-01'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In below two boxes, we are attempting to run model with only a few columns to simplify an adding back as we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that we don't want:\n",
    "    # months only used for making slices, don't actually need them\n",
    "\n",
    "#employee_matrix.drop(['status','cost_center_name','city','ws_text','first_punch_cost_center',\n",
    "#                      'dept','cost_center_orig','first_ejsi_cost_center', 'end_date',\n",
    "#                     'f1_month','next_month','next_month2','avg_reg_hours','sum_reg_hours',\n",
    "#                     'avg_OT_hours','sum_OT_hours','month','start_date'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# dropping from bmw_demo:\n",
    "# employee_matrix.drop(['start_date','start_date_month','end_date','cost_center_name','org_unit','dept','status',\n",
    "#                       'birth_year','ee_type','first_ejsi_cost_center','f1_month','ws_rule','ws_text','att_month',\n",
    "#                       'cost_center_orig','ejsi_cc','first_punch_cost_center','month',\n",
    "#                      'next_month','next_month2'], axis=1, inplace=True)\n",
    "\n",
    "# dropping from points:\n",
    "#employee_matrix.drop(['name','att_date','att_desc'], axis=1, inplace=True)\n",
    "\n",
    "# dropping from actuals:\n",
    "# employee_matrix.drop(['work_date','category','description','ws_rule','ws_rule_text','status'], axis=1, inplace=True)\n",
    "\n",
    "# dropping from quality_daily_hall:\n",
    "# employee_matrix.drop(['f1_date','defect_date','count_non_dp_vins_hall'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "## trying employee_matrix with only a few of the columns for simplicity and debugging:\n",
    "\n",
    "employee_matrix = employee_matrix[['badge','label','att_points','cost_center','gender','race','daily_hours','city','avg_OT_hours','avg_reg_hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(len(employee_matrix.att_points)):\n",
    "# #     if employee_matrix.att_points\n",
    "\n",
    "# print(employee_matrix['att_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding:\n",
    "\n",
    "\n",
    "# ensuring all cols with strings are one-hot encoded - can deal with each non-string one hot col manually\n",
    "    # making list of cols with strings and passing to get_dummies function (oneHotList)\n",
    "    \n",
    "oneHotList = []\n",
    "\n",
    "#print(employee_matrix.badge)\n",
    "print(type(employee_matrix.badge.iloc[0]))\n",
    "\n",
    "\n",
    "# part of the below if statement???:\n",
    "# not (np.isnan(employee_matrix[feature].iloc[0])) and \n",
    "for feature in employee_matrix.columns:\n",
    "    #print('feature is: ', feature)\n",
    "    # do nan values have a type?\n",
    "        # first part of if statement to short-circuit just in case they don't\n",
    "    # checking first value in a column, if it is a string or not\n",
    "    if type(employee_matrix[feature].iloc[0]) is str:\n",
    "        oneHotList.append(feature)\n",
    "        \n",
    "# add all cols to be one-hot-encoded that do not have strings manually:\n",
    "\n",
    "#oneHotList.extend(('cost_center','hall','daily_hours','zip_code'))\n",
    "\n",
    "\n",
    "# use line above for final:\n",
    "\n",
    "oneHotList.extend(('cost_center','daily_hours'))\n",
    "\n",
    "#print('oneHotList is: ', oneHotList)\n",
    "# employee_matrix = pd.get_dummies(data=employee_matrix, columns = ['cost_center','gender','race','hall','shift',\n",
    "#                                                          'daily_hours','zip_code','line_loc','city'], drop_first = True)\n",
    "\n",
    "employee_matrix = pd.get_dummies(data=employee_matrix, columns=oneHotList, drop_first = True)\n",
    "\n",
    "# make sure to one-hot encode line_loc from employee_matrix!!\n",
    "\n",
    "# difference in value between badge numbers is not important, guy with badge number 40 is 2x better than 20\n",
    "    # the specific badge number has no heeding if you're fired\n",
    "    \n",
    "# employee_matrix = oneHot.fillna(0)\n",
    "\n",
    "# iterate through all columns in df, if a singline na value in a column, fill all na's with mean from that column\n",
    "    # imputing withiout sklearn\n",
    "    \n",
    "#featureArr = np.array(employee_matrix.columns)\n",
    "\n",
    "#for feature in featureArr:\n",
    "#    print('old column is: ')\n",
    "#    print('\\n')\n",
    "#    print(employee_matrix[feature])\n",
    "#    employee_matrix[feature].fillna(employee_matrix[feature].mean(), inplace=True)\n",
    "#    print('\\n')\n",
    "#    print('new column is: ')\n",
    "#    print('\\n')\n",
    "#    print(employee_matrix[feature])\n",
    "#employee_matrix = employee_matrix.fillna(0)\n",
    "\n",
    "#employee_matrix.to_csv(\"trial_one_hot_encoding_employee_matrix.csv\")\n",
    "\n",
    "# imputing with sklearn:\n",
    "\n",
    "\n",
    "# try 4 sklearn:\n",
    "\n",
    "#print(employee_matrix.sum_OT_hours)\n",
    "# imputer function removes all columns that only have NAN.. for some reason some of our columns have only NAN\n",
    "    # get rid of them before imputing\n",
    "\n",
    "# removing all columns that have ONLY NAN values:\n",
    "employee_matrix=employee_matrix.dropna(axis=1, how='all')\n",
    "\n",
    "# fill att_points with 0, not mean\n",
    "employee_matrix['att_points'].fillna(0, inplace=True)\n",
    "\n",
    "print(employee_matrix['att_points'])\n",
    "\n",
    "fill_NaN = Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
    "imputed_employee_matrix= pd.DataFrame(fill_NaN.fit_transform(employee_matrix))\n",
    "#print(len(employee_matrix.columns))\n",
    "#print(len(imputed_employee_matrix.columns))\n",
    "#employee_matrix.head()\n",
    "#imputed_employee_matrix.head()\n",
    "\n",
    "imputed_employee_matrix.columns = employee_matrix.columns\n",
    "imputed_employee_matrix.index = employee_matrix.index\n",
    "\n",
    "employee_matrix = imputed_employee_matrix\n",
    "\n",
    "\n",
    "# try 2 sklearn:\n",
    "\n",
    "#featureList = list(employee_matrix.columns)\n",
    "\n",
    "#print(featureList)\n",
    "\n",
    "#imputer = Imputer(missing_values ='NaN', strategy = 'mean', axis = 0)\n",
    "\n",
    "#q=imputer.fit_transform(employee_matrix[featureList]).T\n",
    "\n",
    "#employee_matrix[featureList]=q\n",
    "\n",
    "\n",
    "# try 3 sklearn\n",
    "\n",
    "#imp=Imputer(missing_values=\"NaN\", strategy=\"mean\" )\n",
    "\n",
    "#employee_matrix[featureList]=imp.fit_transform(employee_matrix[[featureList]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#employee_matrix.head()\n",
    "\n",
    "\n",
    "#print(np.array(employee_matrix.columns))\n",
    "#roc = np.array(employee_matrix.columns)\n",
    "#print(type(roc))\n",
    "#print(type(roc[5]))\n",
    "#employee_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRIAL:\n",
    "\n",
    "shuff_try = [employee_matrix for _, employee_matrix in employee_matrix.groupby('badge')]\n",
    "random.shuffle(shuff_try)\n",
    "\n",
    "#print(shuff_try)\n",
    "\n",
    "employee_matrix = pd.concat(shuff_try)\n",
    "#print(type(employee_matrix))\n",
    "#print(employee_matrix)\n",
    "#employee_matrix.to_csv('trial_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(employee_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 month slices of peoples history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could dictionaries based on badge here as well as in the creation of employee matrix be quicker/more efficient?\n",
    "\n",
    "# later: - MAKE SURE TO DELETE DATA WITH LESS THAN 4 MONTHS WORKED \n",
    "employee_slices = []\n",
    "label_list=[]\n",
    "\n",
    "print(type(employee_matrix))\n",
    "for badge in employee_matrix['badge'].unique():\n",
    "    df = employee_matrix[employee_matrix.badge==badge]\n",
    "    #print(df)\n",
    "    #print(df)\n",
    "    df_length = len(df)\n",
    "    if df_length >= 4:\n",
    "        # get rid of people who worked less than 4 months and don't have enough data to predict if they left or not.\n",
    "        for i in range(df_length - 2): #get slices of 3 months\n",
    "            df_slice = (df[i: i+3])\n",
    "            employee_slices.append(df_slice)\n",
    "            label = df_slice.iloc[-1]['label']\n",
    "            label_list.append(label)\n",
    "        \n",
    "# print(type(employee_slices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(employee_matrix[employee_matrix.badge==badge])\n",
    "#print(employee_matrix.badge==badge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open jupyter in terminal with the below line so that this cell will run properly:\n",
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000\n",
    "\n",
    "# first try not flattening it, if we want to flatten, just had .flatten() to the end of .to_numpy():\n",
    "\n",
    "# drop label and badge column from all df's in train and test:\n",
    "    \n",
    "X_input = [None for i in range(len(employee_slices))]\n",
    "\n",
    "#shuff_try = [employee_matrix for _, employee_matrix in employee_matrix.groupby('badge')]\n",
    "#random.shuffle(shuff_try)\n",
    "\n",
    "# X_input, y_input = shuffle(X_input, y_input, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# Try upsampling Natalie's way:\n",
    "\n",
    "\n",
    "\n",
    "# don't drop badge here for now:\n",
    "for i in range(len(employee_slices)):\n",
    "    employee_slices[i] = employee_slices[i].drop(['label'], axis=1)\n",
    "    \n",
    "for i in range(len(employee_slices)):\n",
    "    X_input[i] = employee_slices[i].values\n",
    "    \n",
    "    \n",
    "X_input = np.array(X_input)\n",
    "print(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making y_train:\n",
    "y_input = np.array(label_list)\n",
    "#print(len(label_list))\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to shuffle these here:\n",
    "# randomize employee_slices and label_list with same seed so that all 1.0's aren't first and up in training set:\n",
    "    # Also, make sure that same people are also in training or test only, or this could get messy\n",
    "        # how will that be possible????!! - perhaps it has to happen above\n",
    "#X_input, y_input = shuffle(X_input, y_input, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating testing data (train/test split):\n",
    "\n",
    "# 80% of data is training, 20% is for testing\n",
    "    #X_train is now 80% of its previous size, other 20% is now testing\n",
    "\n",
    "    \n",
    "# make sure to not have same person in training and test data!\n",
    "\n",
    "    # pick a percentage of badges at random (80%)\n",
    "    # don't want only older people in training, newer in testing\n",
    "    \n",
    "train_size = int(len(X_input) * 0.80)\n",
    "test_size = len(X_input) - train_size\n",
    "\n",
    "X_train, X_test = X_input[0:train_size], X_input[train_size:len(X_input)]\n",
    "\n",
    "y_train, y_test = y_input[0:train_size], y_input[train_size:len(y_input)]\n",
    "    \n",
    "\n",
    "#print(len(y_train))\n",
    "#print(len(X_train))\n",
    "#print(len(y_test))\n",
    "#print(len(X_test))\n",
    "\n",
    "# print(X_train)\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "\n",
    "# print(y_train)\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "\n",
    "# print(X_test)\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "# print('\\n')\n",
    "\n",
    "# print(y_test)\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Oversampling:\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "# print(type(X_train))\n",
    "# print(type(X_train[0]))\n",
    "# print(type(X_train[0][0]))\n",
    "\n",
    "zeroCount = 0\n",
    "oneCount = 0\n",
    "for item in y_train:\n",
    "    if item == 0:\n",
    "        zeroCount +=1\n",
    "    elif item == 1:\n",
    "        oneCount +=1\n",
    "\n",
    "print('zeroCount is: ', zeroCount)\n",
    "print('oneCount is: ', oneCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select samples (1-month slices) to be copied and appended to the end of the array\n",
    "\n",
    "# try adding samples of 1.0 class with a while loop???\n",
    "\n",
    "orig_y_train_len = len(y_train)\n",
    "\n",
    "# prop is guaranteed to be greater than or equal to the proportion zeroCount/OneCount\n",
    "\n",
    "prop = (zeroCount//oneCount)+1    \n",
    "# print(prop)\n",
    "\n",
    "# prop = 2\n",
    "\n",
    "# going through X_train, and retrieving all samples that are of the minority (1) class:\n",
    "    #make list first, convert to numpy array once at desired size\n",
    "\n",
    "onesOnlyTrainX = []\n",
    "onesOnlyTrainY = []\n",
    "\n",
    "# don't believe i need to index with i%orig_y_train_len here.... just want all examples of 1\n",
    "for i in range(orig_y_train_len):\n",
    "    if y_train[i] == 1:\n",
    "        onesOnlyTrainX.append(X_train[i])\n",
    "        onesOnlyTrainY.append(y_train[i])\n",
    "        \n",
    "print('length onesOnlyTrainY is: ', len(onesOnlyTrainY))\n",
    "print('length onesOnlyTrainX orig is: ', len(onesOnlyTrainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(onesOnlyTrainX)\n",
    "\n",
    "# convert to arrays from lists\n",
    "onesOnlyTrainX = np.array(onesOnlyTrainX)\n",
    "onesOnlyTrainY = np.array(onesOnlyTrainY)\n",
    "\n",
    "# want to add the ORIGINAL onesOnlyTrainX, so we add same amount every time and doesn't get exponential:\n",
    "onesOnlyTrainXOrig = copy.deepcopy(onesOnlyTrainX)\n",
    "onesOnlyTrainYOrig = copy.deepcopy(onesOnlyTrainY)\n",
    "\n",
    "# append onesOnlyTrainX to itself prop times: (dynamic)\n",
    "    # len(onesOnlyTrainX) guaranteed to be greater than or equal to zeroCount due to prop\n",
    "for i in range(prop):\n",
    "    onesOnlyTrainX = np.vstack((onesOnlyTrainX, onesOnlyTrainXOrig))\n",
    "    onesOnlyTrainY = np.append(onesOnlyTrainY, onesOnlyTrainYOrig)\n",
    "    \n",
    "print('length onesOnlyTrainX Final: ', len(onesOnlyTrainX))\n",
    "print('length onesOnlyTrainY Final: ', len(onesOnlyTrainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle after appending them:\n",
    "    # ensuring they are shuffled in same order\n",
    "\n",
    "indices = np.arange(onesOnlyTrainY.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "onesOnlyTrainY = onesOnlyTrainY[indices]\n",
    "onesOnlyTrainX = onesOnlyTrainX[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for modular arithmetic:\n",
    "\n",
    "# going through the list of shuffled months with corresponding 1.0 category, and adding them to X_train until ...\n",
    "    #... same amount of both categories\n",
    "i = 0\n",
    "while oneCount < zeroCount:\n",
    "        X_train = np.vstack((X_train, [onesOnlyTrainX[i]]))\n",
    "        # also make sure to change y_train accordingly to still match with X_train:\n",
    "        y_train = np.append(y_train, onesOnlyTrainY[i])\n",
    "        \n",
    "        oneCount+=1\n",
    "        i+=1\n",
    "        #print('i is: ', i)\n",
    "        #print('oneCount is: ', oneCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps shuffle X_train and y_train again after creating them???? probably not helpful...\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring that same amount of majority and minority class in each:\n",
    "oneCountFinal = 0\n",
    "zeroCountFinal = 0\n",
    "for item in y_train:\n",
    "    if item == 0:\n",
    "        zeroCountFinal +=1\n",
    "    elif item == 1:\n",
    "        oneCountFinal +=1\n",
    "\n",
    "print(oneCountFinal)\n",
    "print(zeroCountFinal)\n",
    "#print(X_train)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "# print(X_train.shape[0])\n",
    "# print(X_train.shape[1])\n",
    "# print(X_train.shape[2])\n",
    "print(X_train)\n",
    "print('\\n')\n",
    "print(y_train)\n",
    "\n",
    "plt.hist(y_train)\n",
    "\n",
    "# badge in first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop badge right before we train the model:\n",
    "    # have to iterate through both train and test and drop\n",
    "        # X_train y_train, X_test, y_test\n",
    "    \n",
    "\n",
    "# drop badge from training data:\n",
    "    # is it the first column??\n",
    "# for i in range(len(y_train)):\n",
    "#     for j in range(len(y_train[i])):\n",
    "        \n",
    "#     employee_slices[i] = employee_slices[i].drop(['badge'], axis=1)\n",
    "\n",
    "X_train = X_train[:, :, 1:]\n",
    "# y_train = y_train[1:]\n",
    "\n",
    "X_test = X_test[:, :, 1:]\n",
    "# y_test = y_test[1:]\n",
    "\n",
    "print(X_train)\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "# checking that types are the same:\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'binary_crossentropy'\n",
    "\n",
    "# if loss == 'sparse_categorical_crossentropy':\n",
    "#     for i in range(len(y_test)):\n",
    "#         if y_test[i][0] == 1:\n",
    "#             y_test[i][0] = 0.99\n",
    "    \n",
    "#     for j in range(len(X_test)):\n",
    "#         if X_test[j][0] == 1:\n",
    "#             X_test[j][0] = 0.99\n",
    "\n",
    "\n",
    "print('training model')\n",
    "print('\\n')\n",
    "\n",
    "# Actually building the net:\n",
    "\n",
    "# print(X_train.shape[0])\n",
    "# print(X_train.shape[1])\n",
    "# print(X_train.shape[2])\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(\n",
    "  units=31,\n",
    "    return_sequences = True,\n",
    "  input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "))\n",
    "# change return_sequences to true if adding additional LSTM layer\n",
    "\n",
    "model.add(keras.layers.LSTM(units=250, return_sequences = True))\n",
    "model.add(keras.layers.LSTM(units=1000))\n",
    "# model.add(keras.layers.LSTM(units=1500))\n",
    "model.add(keras.layers.Dense(activation='sigmoid',units=1))\n",
    "model.compile(\n",
    "  loss= loss,\n",
    "    # try categorical crossentropy\n",
    "  optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "  metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "# class_weight= {0:10.,\n",
    "#                1:1.}\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=1,\n",
    "    #class_weight=class_weight,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# try adding another LSTM layer - might increase accuracy - tried\n",
    "# adjust loss and accuracy functiond - tried\n",
    "# try weights with no upsampling - tried\n",
    "    # try weightd with Upsampling - tried, no effet\n",
    "# google ways to increase precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test,verbose=2)\n",
    "# second line of output is just (loss, accuracy) I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION: Testing the results of our model:\n",
    "\n",
    "## Predicting one value:\n",
    "\n",
    "# emptyList = [0]\n",
    "# emptyList[0] = X_test[0]\n",
    "\n",
    "# emptyArray = np.array(emptyList)\n",
    "\n",
    "# y_pred = model.predict(emptyArray)\n",
    "\n",
    "#print(y_pred)\n",
    "\n",
    "\n",
    "## Predicting from entire X_test:\n",
    "\n",
    "y_pred3 = model.predict(X_test)\n",
    "\n",
    "print(y_pred3)\n",
    "\n",
    "# the probability is the probability that they will get fired in the next month from a three month segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicting the results for the entire test dataset:\n",
    "\n",
    "#y_pred2 = model.predict(X_test)\n",
    "#print(\"y_pred2 is: \", y_pred2)\n",
    "\n",
    "# A random predicted value in the dataset:\n",
    "\n",
    "#print(\"y_pred2[32] is: \", y_pred2[32])\n",
    "\n",
    "\n",
    "# compare y_test with the prediction from X_test in above cell:\n",
    "#print(y_test)\n",
    "#print(type(y_test[5]))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking accuracy of model for each class, separately:\n",
    "\n",
    "# Y_test = np.argmax(y_test) # Convert one-hot to index\n",
    "\n",
    "y_pred4 = model.predict_classes(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred4))\n",
    "\n",
    "# confusion matrix:\n",
    "confusion_matrix(y_test, y_pred4, labels=[0,1])\n",
    "\n",
    "# remember that X_test does not need to be balanced, only X_train\n",
    "    # the fact that X_test isn't balanced doesn't affect our results at all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred4)\n",
    "#print(len(y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the model:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
